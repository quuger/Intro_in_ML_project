{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c547c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_ROOT = Path(\"..\").resolve()\n",
    "RAW_JSON = REPO_ROOT / \"raw_data\" / \"messages.json\"\n",
    "\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "print(\"Repo root:\", REPO_ROOT)\n",
    "print(\"Raw JSON:\", RAW_JSON, \"exists:\", RAW_JSON.exists())\n",
    "\n",
    "from topic_segmentor import ReplyChainTopicSegmentor\n",
    "\n",
    "topic_size = 4\n",
    "reply_seg = ReplyChainTopicSegmentor(topic_size=topic_size, non_overlapping=True)\n",
    "gold_topics = reply_seg.get_topics(str(RAW_JSON))\n",
    "\n",
    "print(\"Gold topics:\", len(gold_topics))\n",
    "print(\"First 3 sizes:\", [len(t) for t in gold_topics[:3]])\n",
    "assert all(len(t) == topic_size for t in gold_topics), \"gold_topics must be fixed size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9478d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class WindowExampleRaw:\n",
    "    msgs: list\n",
    "    y: int\n",
    "    ts_end: int\n",
    "\n",
    "def window_to_text(msgs) -> str:\n",
    "    return \"\\n\".join([f\"{m.user}: {m.text}\" for m in msgs])\n",
    "\n",
    "def ctx_to_text(msgs) -> str:\n",
    "    return \"\\n\".join([f\"{m.user}: {m.text}\" for m in msgs[:-1]])\n",
    "\n",
    "def resp_to_text(msgs) -> str:\n",
    "    m = msgs[-1]\n",
    "    return f\"{m.user}: {m.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0b3b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_size = 4\n",
    "assert all(len(t) == topic_size for t in gold_topics)\n",
    "\n",
    "pos_raw = [WindowExampleRaw(msgs=t, y=1, ts_end=t[-1].timestamp) for t in gold_topics]\n",
    "print(\"Pos:\", len(pos_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e722eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "rng = random.Random(42)\n",
    "\n",
    "contexts = [ctx_to_text(t) for t in gold_topics]\n",
    "responses = [resp_to_text(t) for t in gold_topics]\n",
    "\n",
    "tfidf_miner = TfidfVectorizer(lowercase=True, max_features=50000, ngram_range=(1,2))\n",
    "tfidf_miner.fit(contexts + responses)\n",
    "\n",
    "C = tfidf_miner.transform(contexts)\n",
    "R = tfidf_miner.transform(responses)\n",
    "\n",
    "S = cosine_similarity(C, R)\n",
    "\n",
    "np.fill_diagonal(S, -1.0)\n",
    "\n",
    "def mined_negative_window(i: int, topk: int = 50) -> List:\n",
    "    best_idx = np.argpartition(S[i], -topk)[-topk:]\n",
    "    best_idx = best_idx[np.argsort(S[i][best_idx])[::-1]]\n",
    "\n",
    "    for j in best_idx:\n",
    "        if j != i:\n",
    "            return gold_topics[i][:-1] + [gold_topics[j][-1]]\n",
    "    j = rng.randrange(len(gold_topics))\n",
    "    while j == i:\n",
    "        j = rng.randrange(len(gold_topics))\n",
    "    return gold_topics[i][:-1] + [gold_topics[j][-1]]\n",
    "\n",
    "neg_per_pos = 2\n",
    "neg_raw = []\n",
    "for i in range(len(gold_topics)):\n",
    "    for _ in range(neg_per_pos):\n",
    "        w = mined_negative_window(i, topk=50)\n",
    "        neg_raw.append(WindowExampleRaw(msgs=w, y=0, ts_end=w[-1].timestamp))\n",
    "\n",
    "print(\"Neg (hard-mined):\", len(neg_raw))\n",
    "print(\"\\nExample HARD NEG window:\\n\", window_to_text(neg_raw[0].msgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acab14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_raw = sorted(pos_raw + neg_raw, key=lambda e: e.ts_end)\n",
    "\n",
    "split = int(len(dataset_raw) * 0.8)\n",
    "train_raw = dataset_raw[:split]\n",
    "test_raw  = dataset_raw[split:]\n",
    "\n",
    "print(\"Train:\", len(train_raw), \"Test:\", len(test_raw))\n",
    "print(\"Train pos rate:\", sum(e.y for e in train_raw)/len(train_raw))\n",
    "print(\"Test  pos rate:\", sum(e.y for e in test_raw)/len(test_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_for_tfidf = [window_to_text(e.msgs) for e in train_raw]\n",
    "tfidf_feat = TfidfVectorizer(lowercase=True, max_features=50000, ngram_range=(1,2))\n",
    "tfidf_feat.fit(train_text_for_tfidf)\n",
    "\n",
    "def tfidf_cos(a: str, b: str) -> float:\n",
    "    X = tfidf_feat.transform([a, b])\n",
    "    return float(cosine_similarity(X[0], X[1])[0,0])\n",
    "\n",
    "def featurize_window(ex: WindowExampleRaw) -> np.ndarray:\n",
    "    msgs = ex.msgs\n",
    "    ctx = msgs[:-1]\n",
    "    resp = msgs[-1]\n",
    "\n",
    "    ctx_text = \"\\n\".join([f\"{m.user}: {m.text}\" for m in ctx])\n",
    "    resp_text = f\"{resp.user}: {resp.text}\"\n",
    "\n",
    "    sim_ctx_resp = tfidf_cos(ctx_text, resp_text)\n",
    "\n",
    "    dt12 = max(0, msgs[1].timestamp - msgs[0].timestamp)\n",
    "    dt23 = max(0, msgs[2].timestamp - msgs[1].timestamp)\n",
    "    dt34 = max(0, msgs[3].timestamp - msgs[2].timestamp)\n",
    "\n",
    "    max_dt_neighbors = max(dt12, dt23, dt34)\n",
    "    log_dt34 = float(np.log1p(dt34))\n",
    "\n",
    "    users = [m.user for m in msgs]\n",
    "    num_unique_users = len(set(users))\n",
    "    resp_user_seen = 1.0 if resp.user in [m.user for m in ctx] else 0.0\n",
    "\n",
    "    question_in_last_context = 1.0 if \"?\" in ctx[-1].text else 0.0\n",
    "\n",
    "    return np.array([\n",
    "        sim_ctx_resp,\n",
    "        float(np.log1p(max_dt_neighbors)),\n",
    "        log_dt34,\n",
    "        float(num_unique_users),\n",
    "        resp_user_seen,\n",
    "        question_in_last_context\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "X_train = np.vstack([featurize_window(e) for e in train_raw])\n",
    "y_train = np.array([e.y for e in train_raw], dtype=np.int64)\n",
    "\n",
    "X_test  = np.vstack([featurize_window(e) for e in test_raw])\n",
    "y_test  = np.array([e.y for e in test_raw], dtype=np.int64)\n",
    "\n",
    "feature_names = [\n",
    "    \"tfidf_sim_ctx_resp\",\n",
    "    \"log1p_max_dt_neighbors\",\n",
    "    \"log1p_dt34\",\n",
    "    \"num_unique_users\",\n",
    "    \"resp_user_seen_in_context\",\n",
    "    \"question_in_last_context\",\n",
    "]\n",
    "\n",
    "X_train.shape, y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4625ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "gbdt = HistGradientBoostingClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.08,\n",
    "    max_iter=400,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "gbdt.fit(X_train, y_train)\n",
    "\n",
    "proba = gbdt.predict_proba(X_test)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_test, pred, average=\"binary\", zero_division=0)\n",
    "auc = roc_auc_score(y_test, proba)\n",
    "\n",
    "print({\"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1, \"ROC_AUC\": auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cbaa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(tfidf_feat, REPO_ROOT / \"models/tfidf_feat.joblib\")\n",
    "joblib.dump(gbdt, REPO_ROOT / \"models/gbdt_topic_window.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, roc_auc_score, classification_report\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=1200,\n",
    "    max_depth=None\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=4,\n",
    "    max_features=\"sqrt\"\n",
    "    class_weight=\"balanced\",\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "proba = rf.predict_proba(X_test)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_test, pred, average=\"binary\", zero_division=0)\n",
    "auc = roc_auc_score(y_test, proba)\n",
    "\n",
    "print({\"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1, \"ROC_AUC\": auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5e7cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, roc_auc_score, classification_report\n",
    ")\n",
    "\n",
    "logreg = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\", LogisticRegression(max_iter=5000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "proba_lr = logreg.predict_proba(X_test)[:, 1]\n",
    "pred_lr = (proba_lr >= 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, pred_lr)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_test, pred_lr, average=\"binary\", zero_division=0)\n",
    "auc = roc_auc_score(y_test, proba_lr)\n",
    "\n",
    "print(\"LogReg metrics:\", {\"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1, \"ROC_AUC\": auc})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
